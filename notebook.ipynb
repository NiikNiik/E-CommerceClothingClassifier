{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa02648-9eae-45ba-893f-88440e8e4235",
   "metadata": {},
   "source": [
    "![clothing_classification](clothing_classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a988c-1095-485a-a88c-002400a872be",
   "metadata": {},
   "source": [
    "Fashion Forward is a new AI-based e-commerce clothing retailer.\n",
    "They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n",
    "\n",
    "As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1ab317-f3e4-4e5f-93a7-9c27677c5ffb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1720631742784,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Run the cells below first"
   },
   "outputs": [],
   "source": [
    "# Run the cells below first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e7dae3-c192-4267-a0ed-18d1ac56c861",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13008,
    "lastExecutedAt": 1720631755792,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install torchmetrics\n!pip install torchvision",
    "outputsMetadata": {
     "0": {
      "height": 544,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from torchmetrics) (2.3.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from torchmetrics) (0.11.3.post0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.1 in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\niko ajani\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1473c8-19ea-46cf-8621-46b375fe1e11",
   "metadata": {},
   "source": [
    "This code imports necessary libraries:\n",
    "\n",
    "numpy for numerical operations.\n",
    "torch and its submodules for building and training neural networks.\n",
    "torchmetrics for performance metrics.\n",
    "torchvision and its submodules for loading datasets and transforming images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8065b7-84fc-4376-afef-6db731dec4b3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54,
    "lastExecutedAt": 1720631755848,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94c913-d1b9-497f-8141-edfbc63e7277",
   "metadata": {},
   "source": [
    "This code loads the FashionMNIST dataset:\n",
    "\n",
    "train_data contains training images and labels.\n",
    "test_data contains test images and labels.\n",
    "The transform=transforms.ToTensor() converts images to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662e1bf1-943f-4243-9fd4-02ce11609e8d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 146,
    "lastExecutedAt": 1720631755994,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     },
     "2": {
      "height": 122,
      "type": "stream"
     },
     "3": {
      "height": 38,
      "type": "stream"
     },
     "4": {
      "height": 122,
      "type": "stream"
     },
     "5": {
      "height": 38,
      "type": "stream"
     },
     "6": {
      "height": 122,
      "type": "stream"
     },
     "7": {
      "height": 38,
      "type": "stream"
     },
     "8": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e899e-fd5b-4413-9e86-f7417e876daa",
   "metadata": {},
   "source": [
    "This code extracts dataset information:\n",
    "\n",
    "classes is a list of class names.\n",
    "num_classes is the number of classes.\n",
    "num_input_channels is 1 (since FashionMNIST images are grayscale).\n",
    "    \"grayscale\" refers to images that contain shades of gray rather than colors.\n",
    "num_output_channels is the number of output channels for the convolutional layer.\n",
    "image_size is the height (and width, as images are square) of the images.\n",
    "    The size of the input images (the images are 28x28 pixels, image_size will be 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c0a71d-d7d9-4a11-8a9b-55867ea7e0b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1720631756044,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Get the number of classes\nclasses = train_data.classes\nnum_classes = len(train_data.classes)\n\n# Define some relevant variables\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]\n"
   },
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "classes = train_data.classes\n",
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Define some relevant variables\n",
    "num_input_channels = 1\n",
    "num_output_channels = 16\n",
    "image_size = train_data[0][0].shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1336d0c-a483-4b04-af1c-ed8b18014bbc",
   "metadata": {},
   "source": [
    "init method initializes layers: a convolutional layer, ReLU activation, max-pooling layer, flattening layer, and fully connected layer.\n",
    "forward method defines the forward pass: data flows through each layer sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55cd607c-a466-4eb5-99df-9e51e18a66f0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1720631756096,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define CNN\nclass MultiClassImageClassifier(nn.Module):\n    \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x\n"
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "class MultiClassImageClassifier(nn.Module):\n",
    "    \n",
    "    # Define the init method\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassImageClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Create a fully connected layer\n",
    "        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass inputs through each layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7ca80-52c5-4214-bd88-b42499482bed",
   "metadata": {},
   "source": [
    "This code creates a DataLoader for the training data:\n",
    "\n",
    "batch_size=10 specifies the number of samples per batch.\n",
    "shuffle=True shuffles the data at every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb66547c-b99f-4a71-a841-316bf7962c10",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 59,
    "lastExecutedAt": 1720631756156,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "     \n# Define the training set DataLoader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)"
   },
   "outputs": [],
   "source": [
    "     \n",
    "# Define the training set DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43400862-9761-4e35-a39e-42e406acf98c",
   "metadata": {},
   "source": [
    "This code defines the training loop:\n",
    "\n",
    "criterion is the loss function.\n",
    "The loop iterates over epochs and batches.\n",
    "For each batch, it zeroes gradients, computes outputs, calculates loss, backpropagates, and updates weights.\n",
    "It tracks and prints the average loss per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f604adc6-f507-4318-b545-b685c0877b8f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1720631756208,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "\n# Define training function\ndef train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n        \n    train_loss = running_loss / len(dataloader_train)"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define training function\n",
    "def train_model(optimizer, net, num_epochs):\n",
    "    num_processed = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        num_processed = 0\n",
    "        for features, labels in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_processed += len(labels)\n",
    "        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n",
    "        \n",
    "    train_loss = running_loss / len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33243f-d65a-4bc3-ac57-17746ea2303c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47617aac-4b6d-4d47-9765-ead22894975a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 64520,
    "lastExecutedAt": 1720631820728,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "\n# Train for 1 epoch\nnet = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)\n\n# Test the model on the test set\n              \n# Define the test set DataLoader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)\n# Define the metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.042165075822842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train for 1 epoch\n",
    "net = MultiClassImageClassifier(num_classes)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2e501-95f9-41c3-853e-5660ad15bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test set\n",
    "              \n",
    "# Define the test set DataLoader\n",
    "dataloader_test = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")\n",
    "# Define the metrics\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n",
    "recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7039b265-3250-4b4a-b4fe-637e32bb4bb5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11866,
    "lastExecutedAt": 1720631832596,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "\n# Run model on test set\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run model on test set\n",
    "net.eval()\n",
    "predictions = []\n",
    "for i, (features, labels) in enumerate(dataloader_test):\n",
    "    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n",
    "    cat = torch.argmax(output, dim=-1)\n",
    "    predictions.extend(cat.tolist())\n",
    "    accuracy_metric(cat, labels)\n",
    "    precision_metric(cat, labels)\n",
    "    recall_metric(cat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cadaa0d-2f9d-4aed-b98f-bb47acaaf39d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 57,
    "lastExecutedAt": 1720631832655,
    "lastExecutedByKernel": "a42a29f4-e719-40ad-a204-85e369087a99",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Compute the metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8790000081062317\n",
      "Precision (per class): [0.8530954718589783, 0.9876922965049744, 0.8258196711540222, 0.7865448594093323, 0.8270270228385925, 0.9793174862861633, 0.6869834661483765, 0.9278151988983154, 0.9727822542190552, 0.9540459513664246]\n",
      "Recall (per class): [0.8130000233650208, 0.9629999995231628, 0.8059999942779541, 0.9470000267028809, 0.7649999856948853, 0.9470000267028809, 0.6650000214576721, 0.9639999866485596, 0.9649999737739563, 0.9549999833106995]\n"
     ]
    }
   ],
   "source": [
    "# Compute the metrics\n",
    "accuracy = accuracy_metric.compute().item()\n",
    "precision = precision_metric.compute().tolist()\n",
    "recall = recall_metric.compute().tolist()\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (per class):', precision)\n",
    "print('Recall (per class):', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cf9d3-360e-4ba5-8602-2c680c778586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
